//*
//*			Location: LGTMP Stack
//*
//// 		Module Component: labels_scrape
//// 			Description: Scrapes targets for logs based on Docker Containers labels
////
//// 		Labels available:
////  			logs.grafana.com/scrape: true/false
////  			logs.grafana.com/log-format: test/logfmt/clf still need to add others
////			logs.grafana.com/tenant: "primary"


declare "labels_scrape" {

		    /////-------------------------------------------------------\\\\\
		   /////														 \\\\\
		  /////							Arguments						  \\\\\
		 /////															   \\\\\
		/////---------------------------------------------------------------\\\\\

	argument "forward_to" {
		comment = "Must be a list(LogsReceiver) where collected logs should be forwarded to"
	}

	argument "instance_name" {
		optional = true
	}

	argument "label_prefix" {
		comment  = "The label_prefix to use Auto-Scraping (default: logs.grafana.com)"
		default  = "logs.grafana.com"
		optional = true
	}

	argument "__sd_label" {
		optional = true
		comment  = "The logic is used to transform the label_prefix argument into a valid label name by removing unsupported characters."
		default  = replace(replace(replace(coalesce(argument.label_prefix.value, "logs.grafana.com"), ".", "_"), "/", "_"), "-", "_")
	}

	argument "cluster" {
		optional = true
		default  = "docker-compose"
	}

	argument "namespace" {
		optional = true
		default  = "monitoring-system"
	}

	argument "tenant" {
		comment  = "The tenant to write logs to.  This does not have to be the tenantId, this is the value to look for in the logs.grafana.com/tenant label, and this can be a regex. (default: (.*))"
		optional = true
		default  = "(.*)"
	}

		    /////-------------------------------------------------------\\\\\
		   /////														 \\\\\
		  /////						Find Containers						  \\\\\
		 /////															   \\\\\
		/////---------------------------------------------------------------\\\\\

	discovery.docker "dd_logs" {
		host             = "unix:///var/run/docker.sock"
		refresh_interval = "60s"

		filter {
			name   = "status"
			values = ["running"]
		}
	}
		    /////-------------------------------------------------------\\\\\
		   /////														 \\\\\
		  /////						Filter Containers					  \\\\\
		 /////															   \\\\\
		/////---------------------------------------------------------------\\\\\

	discovery.relabel "label_logs_filter" {
		targets = discovery.docker.dd_logs.targets

		rule {																														//* allow resources to declare their metrics scraped or not
			action        = "replace"																										//* example: logs.grafana.com/scrape: false
			source_labels = [
				"__meta_docker_container_label_" + argument.__sd_label.value + "_scrape",
			]
			separator    = ";"
			regex        = "^(?:;*)?(true|false).*$"
			replacement  = "$1"
			target_label = "__tmp_scrape"
		}

		rule { 																															//* drop any targets that have scrape: false
			action        = "drop"
			source_labels = ["__tmp_scrape"]
			regex         = "false"
		}

		rule { 																													//* allow resources to declare their metrics the tenant their metrics should be sent to,
			action        = "keep"																										//* example: logs.grafana.com/tenant: primary
			source_labels = [
				"__meta_docker_container_label_" + argument.__sd_label.value + "_tenant",
			]
			regex = "^(" + argument.tenant.value + ")$"
		}

		rule {																														//* set a default job label to be the namespace/service_name
			action        = "replace"
			source_labels = [
				"__meta_docker_container_label_com_docker_compose_service",
			]
			regex        = "^(?:;*)?([^;]+).*$"
			replacement  = argument.namespace.value + "/$1"
			target_label = "job"
		}

		rule {																														//* allow resources to declare their the job label value to use when collecting their logs, the default value is "",
			action        = "replace"																										//* example: logs.grafana.com/job: "monitoring-system/loki-single-binary"
			source_labels = [
				"__meta_docker_container_label_" + argument.__sd_label.value + "_job",
			]
			separator    = ";"
			regex        = "^(?:;*)?([^;]+).*$"
			replacement  = "$1"
			target_label = "job"
		}

		rule {
			source_labels = ["__meta_docker_container_name"]
			regex         = "/(.*)"
			target_label  = "pod"
		}

		rule {
			source_labels = ["__meta_docker_container_name"]
			regex         = "/(.*)"
			target_label  = "container"
		}

		rule {
			action        = "replace"
			source_labels = [
				"__meta_docker_container_label_com_docker_compose_service",
			]
			regex        = "^(?:;*)?([^;]+).*$"
			replacement  = "$1"
			target_label = "app"
		}

		rule {
			action        = "replace"
			source_labels = [
				"__meta_docker_container_label_app",
			]
			regex        = "^(?:;*)?([^;]+).*$"
			replacement  = "$1"
			target_label = "app"
		}

		rule {																									//* make all labels on the pod available to the pipeline as labels(for loki process),
			action = "labelmap"																								//* they are omitted before write via label allow unless explicitly set
			regex  = "__meta_docker_container_label_(.+)"
		}

		    /////-------------------------------------------------------\\\\\
		   /////														 \\\\\
		  /////						Set Common Labels					  \\\\\
		 /////															   \\\\\
		/////---------------------------------------------------------------\\\\\

		rule {
			action       = "replace"
			replacement  = argument.cluster.value
			target_label = "cluster"
		}

		rule {
			action       = "replace"
			replacement  = argument.namespace.value
			target_label = "namespace"
		}

		rule {
			replacement  = "docker"
			target_label = "tmp_container_runtime"
		}
	}

		    /////-------------------------------------------------------\\\\\
		   /////														 \\\\\
		  /////					Define Loki's Source					  \\\\\
		 /////															   \\\\\
		/////---------------------------------------------------------------\\\\\

	loki.source.docker "lsd_docker_logs" {
		host          = "unix:///var/run/docker.sock"
		targets       = discovery.relabel.label_logs_filter.output
		relabel_rules = discovery.relabel.label_logs_filter.rules

		labels     = {"source" = "docker"}
		forward_to = [loki.process.parse.receiver]
	}

		    /////-------------------------------------------------------\\\\\
		   /////														 \\\\\
		  /////					Container Runtime Parsing				  \\\\\
		 /////															   \\\\\
		/////---------------------------------------------------------------\\\\\

	loki.process "parse" { //* 															Parse the log at container runtime:
		forward_to = argument.forward_to.value

		stage.match { //*																logs.grafana.com/log-format: arr																															//* logs.grafana.com/log-format: test
			pipeline_name = "pipeline for annotation || logs.grafana.com/log-format: arr"															//* sets pipeline and what "format" it is looking for
			selector = "{log_type=\"\", logs_grafana_com_log_format=~\"(?i).*(arr).*\"} |~ \"^(\\\\[[^]]+\\\\])\\\\s+(\\\\w+):\\\\s+(.*)$\""		//! This must be escaped x4 aka \s+ is \\\\s+

			stage.static_labels {
				values = {
					log_type = "arr",																												//* sets the log_type
				}
			}

			stage.regex {
				expression = `\[(?P<level>.*?)\] (?P<extracted_service_name>.*?): (?P<msg>.*)`							//* Must either already have a label in the log, or use a regex to create them such as this
			}

			stage.labels {																															//* set the extracted strings as labels
				values = {																															//! do not forget to add these to the keep-labels.alloy
					level  					= "",
					extracted_service_name 	= "",
					msg 					= "",
				}
			}
		}

		stage.match { //*																logs.grafana.com/log-format: clf
			pipeline_name = "pipeline for annotation || logs.grafana.com/log-format: clf"
			// unescaped regex: \S+\s+\S+\s+\S+\s+\[\S+\s+\S+\]\s+"[^"]+"\s+\d+\s+\d+
			selector = "{log_type=\"\", logs_grafana_com_log_format=~\"(?i).*((apache|nginx|common-?log|clf)).*\"} |~ \"^\\\\S+\\\\s+\\\\S+\\\\s+\\\\S+\\\\s+\\\\[\\\\S+\\\\s+\\\\S+\\\\]\\\\s+\\\"[^\\\"]+\\\"\\\\s+\\\\d+\\\\s+\\\\d+$\""

			// clf doesn't have a log level, set default to info, set the log_type
			stage.static_labels {
				values = {
					level    = "info",
					log_type = "clf",
				}
			}

			// extract the http response code and request method as they might want to be used as labels
			stage.regex {
				// unescaped regex: (?P<response_code>\d{3}) "(?P<request_method>\S+)
				expression = "(?P<response_code>[0-9]{3}) \"(?P<request_method>\\S+)"
			}

			// set the extracted response code and request method as labels
			stage.labels {
				values = {
					response_code  = "",
					request_method = "",
				}
			}

			// check to see if the string failed is found in the log line, if so set the level to error
			stage.match {
				selector = "{logs_grafana_com_log_format=~\"(?i)(apache|nginx|common-log|clf)\"} |~ \" (failed|error) \""

				stage.static_labels {
					values = {
						level = "error",
					}
				}
			}

			// check logs.grafana.com/scrub-timestamp annotation, if true remove the timestamp from the log line
			// this can reduce the overall # of bytes sent and stored in Loki
			stage.match {
				selector      = "{logs_grafana_com_scrub_timestamp=\"true\"}"
				pipeline_name = "pipeline for annotation || logs.grafana.com/scrub-timestamp: true"

				// remove timestamp from the log line
				// unescaped regex: (\[([^\]]+)\])
				stage.replace {
					expression = "(\\[([^\\]]+)\\])"
					replace    = ""
				}
			}
		}

		stage.match { //*																logs.grafana.com/log-format: logfmt
			pipeline_name = "pipeline for annotation || logs.grafana.com/log-format: logfmt"
			// unescaped regex: (\w+=("[^"]*"|\S+))(\s+(\w+=("[^"]*"|\S+)))*\s*
			selector = "{log_type=\"\", logs_grafana_com_log_format=~\"(?i).*(logfmt).*\"} |~ \"(\\\\w+=(\\\"[^\\\"]*\\\"|\\\\S+))(\\\\s+(\\\\w+=(\\\"[^\\\"]*\\\"|\\\\S+)))*\\\\s*\""

			// set the log_type
			stage.static_labels {
				values = {
					log_type = "logfmt",
				}
			}

			// while the level could be extracted as logfmt, this allows for multiple possible log levels formats
			// i.e. loglevel=info, level=info, lvl=info, loglvl=info
			stage.regex {
				expression = "(log)?(level|lvl)=\"?(?P<level>\\S+)\"?"
			}

			// set the extracted level value as a label
			stage.labels {
				values = {
					level = "",
				}
			}

			stage.match {
				selector      = "{logs_grafana_com_scrub_timestamp=\"true\"}"
				pipeline_name = "pipeline for annotation || logs.grafana.com/scrub-timestamp: true"

				// remove timestamp from the log line

				// unescaped regex: ((ts?|timestamp)=\d{4}-\d{2}-\d{2}(T|\s+)\d{2}:\d{2}:\d{2}(\.\d+)?(Z|(\+|-)\d+)?\s+)
				stage.replace {
					expression = "((ts?|timestamp)=[0-9]{4}-[0-9]{2}-[0-9]{2}(T|\\s+)[0-9]{2}:[0-9]{2}:[0-9]{2}(\\.[0-9]+)?(Z|(\\+|-)[0-9]+)?\\s+)"
					replace    = ""
				}
			}

			// check logs.grafana.com/scrub-level annotation, if true remove the level from the log line (it is still a label)
			// this can reduce the overall # of bytes sent and stored in Loki
			stage.match {
				selector      = "{logs_grafana_com_scrub_level=~\"(?i)true\"}"
				pipeline_name = "pipeline for annotation || logs.grafana.com/scrub-level: true"

				// remove level from the log line
				stage.replace {
					// unescaped regex: (log)?(lvl|level)="?[^\s]+\s"?
					expression = "(?i)((log)?(lvl|level)=\"?[^\\s]+\\s\"?)"
					replace    = ""
				}
			}
		}

		stage.match { //*																logs.grafana.com/log-format: json
			pipeline_name = "pipeline for annotation || logs.grafana.com/log-format: json"
			selector      = "{log_type=\"\", logs_grafana_com_log_format=~\"(?i).*((generic-?)?json).*\"} |~ \"^\\\\s*\\\\{.+\\\\}\\\\s*$\""

			// set the log_type
			stage.static_labels {
				values = {
					log_type = "json",
				}
			}

			// extract the level
			stage.json {
				expressions = {
					level = "level || lvl || loglevel || LogLevel || log_level || logLevel || log_lvl || logLvl || levelname || levelName || LevelName",
				}
			}

			// set the extracted level as a label
			stage.labels {
				values = {
					level = "",
				}
			}

			// check logs.grafana.com/scrub-timestamp annotation, if true remove the timestamp from the log line
			// this can reduce the overall # of bytes sent and stored in Loki
			// remove timestamp from the log line, depending on the entry it can be "start_time" or "time"
			stage.match {
				selector      = "{logs_grafana_com_scrub_timestamp=\"true\"}"
				pipeline_name = "pipeline for annotation || logs.grafana.com/scrub-timestamp: true"

				// remove timestamp from the log line
				// unescaped regex: (?i)("(timestamp|ts|logdate|time)"\s*:\s*"[^"]+",?)
				stage.replace {
					expression = "(?i)(\"(timestamp|ts|logdate|time)\"\\s*:\\s*\"[^\"]+\",?)"
					replace    = ""
				}
			}

			// check logs.grafana.com/scrub-level annotation, if true remove the level from the log line (it is still a label)
			// this can reduce the overall # of bytes sent and stored in Loki
			stage.match {
				selector      = "{logs_grafana_com_scrub_level=~\"(?i)true\"}"
				pipeline_name = "pipeline for annotation || logs.grafana.com/scrub-level: true"

				// remove level from the log line
				stage.replace {
					// unescaped regex: (?i)"(log)?(level|lvl)"\s*:\s*"[^"]+",?
					expression = "(?i)(\"(log)?(level|lvl)\"\\s*:\\s*\"[^\"]+\",?)"
					replace    = ""
				}
			}
		}

		stage.match { //*																logs.grafana.com/log-format: syslog
			pipeline_name = "pipeline for annotation || logs.grafana.com/log-format: syslog"
			// unescaped regex: ^[A-Za-z]{3}\s+\d{1,2}\s+\d{2}:\d{2}:\d{2}\s+\S+\s+\S+\[\d+\]:\s+.*$
			selector = "{log_type=\"\", logs_grafana_com_log_format=~\"(?i).*(syslog).*\"} |~ \"^[A-Za-z]{3}\\\\s+\\\\d{1,2}\\\\s+\\\\d{2}:\\\\d{2}:\\\\d{2}\\\\s+\\\\S+\\\\s+\\\\S+\\\\[\\\\d+\\\\]:\\\\s+.*$\""

			stage.static_labels {
				values = {
					// set the log_type
					log_type = "syslog",
					level    = "info",
				}
			}

			// check logs.grafana.com/scrub-timestamp annotation, if true remove the timestamp from the log line
			// this can reduce the overall # of bytes sent and stored in Loki
			stage.match {
				selector      = "{logs_grafana_com_scrub_timestamp=\"true\"}"
				pipeline_name = "pipeline for annotation || logs.grafana.com/scrub-timestamp: true"

				// remove timestamp from the log line
				// unescaped regex: ^[A-Za-z]{3}\s+\d{1,2}\s+\d{2}:\d{2}:\d{2}
				stage.replace {
					expression = "(^[A-Za-z]{3}\\s+\\d{1,2}\\s+\\d{2}:\\d{2}:\\d{2})"
					replace    = ""
				}
			}
		}

			stage.match { //*															assign log level as unkown if it doesn't match any from above
				selector = "{level=\"\"}"

				// default level to unknown
				stage.static_labels {
					values = {
						level = "unknown",
					}
				}
			}

			stage.match { //*															assign log_type as unknown if it doesn't match any from above
				selector = "{log_type=\"\"}"

				// default level to unknown
				stage.static_labels {
					values = {
						log_type = "unknown",
					}
				}
			}

		stage.match { //*																one last attempt to get common log levels using regex
			selector = "{level=\"unknown\"}"

			// unescaped regex: (?i)(?:"(?:level|loglevel|levelname|lvl|SeverityText)":\s*"|\s+(?:level|loglevel|lvl)="?|\s+\[?)(?P<level>(DEBUG?|INFO|WARN(ING)?|ERR(OR)?|CRITICAL|FATAL|NOTICE|TRACE))("|\s+|-|\s*\])
			stage.regex {
				expression = "(?i)(?:\"(?:level|loglevel|levelname|lvl|SeverityText)\":\\s*\"|\\s+(?:level|loglevel|lvl)=\"?|\\s+\\[?)(?P<level>(DEBUG?|INFO|WARN(ING)?|ERR(OR)?|CRITICAL|FATAL|NOTICE|TRACE))(\"|\\s+|-|\\s*\\])"
			}

			// set the extracted level to be a label
			stage.labels {
				values = {
					level = "",
				}
			}
		}

		stage.match { //*																logs.grafana.com/scrub-empties: true/false
			selector      = "{logs_grafana_com_scrub_empties=~\"(?i)(dotnet-?json|istio|(generic-?)?json|log4j-?json|(otel|open-?telemetry)(-?json)?|python-?json)\",logs_grafana_com_scrub_nulls=~\"(?i)true\"}"
			pipeline_name = "pipeline for annotation || logs.grafana.com/scrub-null: true"

			// remove null properties
			stage.replace {
				// unescaped regex: (\s*,\s*("[^"]+"\s*:\s*(\[\s*\]|\{\s*\}|"\s*"))|("[^"]+"\s*:\s*(\[\s*\]|\{\s*\}|"\s*"))\s*,\s*)
				expression = "(\\s*,\\s*(\"[^\"]+\"\\s*:\\s*(\\[\\s*\\]|\\{\\s*\\}|\"\\s*\"))|(\"[^\"]+\"\\s*:\\s*(\\[\\s*\\]|\\{\\s*\\}|\"\\s*\"))\\s*,\\s*)"
				replace    = ""
			}
		}

		stage.match { //*																logs.grafana.com/scrub-nulls: true/false
			selector      = "{logs_grafana_com_scrub_nulls=~\"(?i)(dotnet-?json|istio|(generic-?)?json|log4j-?json|(otel|open-?telemetry)(-?json)?|python-?json)\",logs_grafana_com_scrub_nulls=~\"(?i)true\"}"
			pipeline_name = "pipeline for annotation || logs.grafana.com/scrub-null: true"

			// remove null properties
			stage.replace {
				// unescaped regex: (\s*,\s*("[^"]+"\s*:\s*null)|("[^"]+"\s*:\s*null)\s*,\s*)
				expression = "(\\s*,\\s*(\"[^\"]+\"\\s*:\\s*null)|(\"[^\"]+\"\\s*:\\s*null)\\s*,\\s*)"
				replace    = ""
			}
		}
	}
}
